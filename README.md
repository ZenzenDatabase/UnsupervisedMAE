# HSC-MAE

Abstract—Learning aligned multimodal embeddings from weakly paired, label-free corpora is challenging: pipelines often provide only pre-extracted features, clips contain multiple events, and spurious co-occurrences violate the hard-positive assumptions in contrastive learning. We propose HSC-MAE (Hi- erarchical Semantic Correlation-Aware Masked Autoencoder), a dual-path teacher–student framework that enforces HSC: (i) conditional-sufficiency correlation via sample-level MAE for robustness to partial observation, (ii) canonical-geometry correlation via DCCA for global shared-subspace alignment, and (iii) neighborhood-semantics correlation via teacher-mined soft top-k affinities for local multi-positive structure. Concretely, the student MAE path is trained with reconstruction and a soft top- k InfoNCE using affinity weights; an EMA teacher evaluated on a clean CCA path supplies stable canonical geometry and soft positives. Learnable multi-task weights reconcile competing objectives, and an optional distillation loss transfers teacher geometry into the student. Experiments on AVE and VEGAS show substantial mAP gains over unsupervised baselines, validating that enforcing HSC yields robust audio–visual representation.
